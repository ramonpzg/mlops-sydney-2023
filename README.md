# Building Sound Recommender Systems with Vector Databases


![](images/app_screenshot.png)

## Table of Contents

1. Overview
2. The Data
3. The Tools
4. Setup
5. Next Steps

## 1. Overview

The goal of this project is to build a music recommender system using any kind of music 
and then find the most similar recommendations from a database of songs. The key tool enabling this recommender system is 
[Qdrant](https://qdrant.tech/), "a vector similarity search engine that provides a 
production-ready service with a convenient API to store, search, and manage points - vectors 
with an additional payload."

In order to get a dense representation of our data, the embedding, we will train
a transformer on how to classify different music genres. Once we have a model, we will extract
the hidden layer, add it to Qdrant, define our similarity metric, and begin creating 
our own tunes.

To create our classifier, we will use Facebook's famous 
[Wav2Vec2-Base](https://huggingface.co/facebook/wav2vec2-base) mode. While we will not be finetunning it 
on our set of songs of about 30-seconds each, my hope is that you do so on your own time and have fun with the 
process. We will be using the transformers library, plus a few others and streamlit to create a user interface.

This tutorial was created on a personal laptop with 16 cores, 32GB of RAM, and an Nvidia RTX 2060.

Once you have the environment set up and the unzipped dataset directory, `Audio`, 
inside the `data` directory, you will be able to go through the notebook `tutorial.ipynb`.

## 2. The Data

The dataset can be found on [Kaggle](https://www.kaggle.com/datasets/carlossalazar65/tropical-genres-dataset), 
and you will need to have an account (or create one) to download it. Since music is subject 
to many copyright laws and other legalities, it contains no information other than the many ~30-second clips 
of songs from genres such as Bachata, Merengue, Salsa, Cumbia, and Vallenato. The dataset is particularly appealing 
to me as the first two genres, Bachata and Merengue, were both born in my home country, 
the Dominican Republic.

A few things to note:
- Since we do not know the artist or the name of the song (and because song recognition APIs
are actually very difficult to find and/or not free to use), we will use Fake names generated by `faker` 
to fill in the artist box and we will leave the name of the song in blank for now.
- The dataset does not contain an index so we will create one consisting of a range of digits.


## 3. The Tools

- [`Qdrant`](https://qdrant.tech/) - " is a vector similarity search engine that provides a 
production-ready service with a convenient API to store, search, and manage points - vectors 
with an additional payload."
- [`ðŸ¤— transformers`](https://huggingface.co/docs/transformers/index) - provides APIs and tools 
to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce 
your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch.
- [`ðŸ¤— datasets`](https://huggingface.co/docs/datasets/v2.11.0/en/index) - "is a library for easily 
accessing and sharing datasets for Audio, Computer Vision, and Natural Language Processing (NLP) tasks."
- [`pandas`](https://pandas.pydata.org/) - "is a fast, powerful, flexible and easy to use open source data 
analysis and manipulation tool, built on top of the Python programming language."
- [`NumPy`](https://numpy.org/doc/stable/) - "is a Python library that provides a multidimensional array object, various derived 
objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, 
including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, 
basic linear algebra, basic statistical operations, random simulation and much more."
- [`PyTorch`](https://pytorch.org/docs/stable/index.html) - "is an optimized tensor library for deep learning using GPUs and CPUs."
- [`Faker`](https://faker.readthedocs.io/en/master/) - "is a Python package that generates fake data for 
you. Whether you need to bootstrap your database, create good-looking XML documents, fill-in your persistence 
to stress test it, or anonymize data taken from a production service, Faker is for you."
- [`Streamlit`](https://docs.streamlit.io/) - "is an open-source Python library that makes it easy to create 
and share beautiful, custom web apps for machine learning and data science. In just a few minutes you can 
build and deploy powerful data apps."

## 4. Setup

First, make sure you have [docker](https://docs.docker.com/get-docker/) installed as this is a prerequisite to use Qdrant.

Next, you get started using Qdrant by running the following commands.

```sh
## 1
docker pull qdrant/qdrant

## 2
docker run -p 6333:6333 \
    -v $(pwd)/qdrant_storage:/qdrant/storage \
    qdrant/qdrant
```

Please note, you will need to run the first command above before we get started, but the second is not necessary. 

### Conda Users

#### First Step

Open up your terminal and navigate to a directory of your choosing in your computer. 
Once there, run the following command to get the code for the session.

```sh
 git clone git@github.com:ramonpzg/mlops-sydney-2023.git
```

Conversely, you can click on the green `download` button at the top and donwload all 
files to your desired folder/directory. Once you download it, unzip it and move on to 
the second step.

#### Second Step

To get all dependencies, packages and everything else that would be useful to reproduce 
this project, you can recreate the environment by first going into the directory for the project.

```sh
cd mlops-sydney-2023
```

Then you will need to create an environment with all of the dependancies needed 
for the session by running the following command.

```sh
conda create -n mlops-sydney-2023 python=3.10
conda activate mlops-sydney-2023
conda install --yes --file requirements.txt
# OR
pip install -f requirements.txt


## Conversely

python -m venv venv

python -m venv venv
source venv/bin/activate
pip install -f requirements.txt
```

#### Third Step

Open up VSCode or Jupyter Lab and you should be ready to go.

```sh
jupyter lab

# or

code .
```