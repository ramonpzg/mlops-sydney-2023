{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41f17569-20e2-402d-ae4e-a7a8d55295de",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Recommendation Systems, Vector Databases, and Music"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903f83d2",
   "metadata": {},
   "source": [
    "![main](../images/main_pic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690196c5",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ede68f",
   "metadata": {},
   "source": [
    "1. Overview\n",
    "2. The Challenge\n",
    "3. Audio Data\n",
    "    - Intro\n",
    "    - Data Prep\n",
    "4. Vector Databases\n",
    "    - Why do we need them?\n",
    "    - How can we use them?\n",
    "    - Enter Qdrant\n",
    "        - Getting Started\n",
    "        - Adding Points\n",
    "        - Payloads\n",
    "        - Search\n",
    "5. Models and Vector Representations\n",
    "6. Putting it all together\n",
    "7. Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45dab1c",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98a101",
   "metadata": {},
   "source": [
    "Vector databases are a relatively new way for interacting with abstract data representations derived from opaque machine learning models -- deep learning architectures being the most common ones. These representations are often called vectors or embeddings and they are a compressed version of the data used to train a machine learning model to accomplish a task (e.g., sentiment analysis, speech recognition, object detection, and many more).\n",
    "\n",
    "Vector databases shine in many applications like semantic search and recommendation systems, and in this tutorial, we'll learn about how to build these two kinds of applications using [Qdrant](qdrant.tech), vector similarity search engine that provides a production-ready service with a convenient API to store, search, and manage points (i.e. vectors) with an additional payload.\n",
    "\n",
    "Now, a tutorial is most useful when it involves a real use case, so let's go ahead and describe ours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d844a022",
   "metadata": {},
   "source": [
    "## 2. The Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811a13f",
   "metadata": {},
   "source": [
    "Building recommendation systems can be quite challenging. For starters, we never know apriori the needs and wants of the new customer of a store or the new user of a mobile app, and this makes is difficult to recommend, say, a toaster brand to someone searching for skillets at a store, or a Beatles' song to new users that just listened to a bachata by Romeo Santos and Drake.\n",
    "\n",
    "The aforementioned problems -- \"new user\" == \"no data\" -- belong to the \"cold start\" family of problems in recommender systems and, while these problems might not go away anytime soon, there are ways to bypass them and serve relevant results from the get go, and one answer is vector databases. That said, that's what we will work on in this tutorial, we will build a music recommendation system on top of Qdrant.\n",
    "\n",
    "Music data can be quite challenging to use given that most of it is copyright-protected so chances are you will need to find your data yourself to work on your use-case, use copyright-free music, or see if there is a non-conventional way to bypass the legal barriers around music data. That said, there's a latin music dataset in Kaggle called, [Tropical Genres Dataset](https://www.kaggle.com/datasets/carlossalazar65/tropical-genres-dataset). It contains 30-second clips of songs from the genres of bachata, salsa, merengue, cumbia, and vallenato. Some of these 30-second clips belong to the same songs and, while that is not ideal, it will work well for educational purposes.\n",
    "\n",
    "Once you download it, you should see the following directories.\n",
    "\n",
    "```sh\n",
    "../data\n",
    "├── Audios\n",
    "│   ├── Bachata\n",
    "│   ├── Cumbia\n",
    "│   ├── Merengue\n",
    "│   ├── Salsa\n",
    "│   └── Vallenato\n",
    "├── Spectograms\n",
    "│   ├── Bachata\n",
    "│   ├── Cumbia\n",
    "│   ├── Merengue\n",
    "│   ├── Salsa\n",
    "│   └── Vallenato\n",
    "```\n",
    "\n",
    "The `Spectograms` directory contains spectograms, which are visual representation of the frequencies present in an audio signal over time. It is a 2D graph where the x-axis represents time and the y-axis represents frequency. The intensity of the color or brightness of the graph indicates the strength or amplitude of the frequencies at a particular time. Here is an example of a Spectogram.\n",
    "\n",
    "![specto](../images/mel_specto.png)\n",
    "\n",
    "If you've ever wonder what audio could look like visually, this is one way to visualize it.\n",
    "\n",
    "Before we get to the recommendation systems part, let's go over what audio data is first. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a01f7",
   "metadata": {},
   "source": [
    "## 3. Audio Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2992d6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6c15638",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29019bf2",
   "metadata": {},
   "source": [
    "Audio data is way of representing sound in a shape and form that can be processed and analyzed by computers. A wide range of applications use audio data and these include music production, telecommunications, and digital assistants like Siri and Alexa.\n",
    "\n",
    "What is Sounds then? Sound is a form of energy that is produced by vibrations or oscillations in a medium such as air, water, or solid objects. When an object vibrates, it creates pressure waves that travel through the surrounding medium, carrying the energy of the vibrations. When speaking to another person, sound is the vibrations in the air coming out of their lungs.\n",
    "\n",
    "When sound becomes audio, it is said to be in a physical or digital format that can be measured per second via one or multiple channels. This measurement per second is called Hertz and we humans can hear anywhere from 20 to 20,000. Some common audio formats contain 44,100 and the higher this number is the better the quality of the sound.\n",
    "\n",
    "\n",
    "For data science use cases, we first divide the data into small segments. Each segment is then processed using a mathematical operation known as the Fourier transform, which breaks down the sound into its component frequencies.\n",
    "\n",
    "After the Fourier transform has been applied, mel-scale filter banks are used to group the frequencies into a set of bands that more closely match the human auditory system's perception of sound. These filter banks amplify some frequency ranges while reducing others. This process results in a set of values for each segment of audio, which can be arranged to form a spectrogram.\n",
    "\n",
    "Mel-spectrograms are useful in machine learning applications as they provide a way to represent audio data in a format that can be easily processed and analyzed by computer vision models.\n",
    "\n",
    "Now that we know a little bit about audio data, let's examine a sample to get an intuition for how the process works.\n",
    "\n",
    "Before you run any line of code, make sure you have \n",
    "1. downloaded the data\n",
    "2. create a virtual environment (if not in Google Colab)\n",
    "3. installed the packages below\n",
    "\n",
    "```bash\n",
    "# with conda or mamba if you have it installed\n",
    "mamba env create -n my_env python=3.10\n",
    "mamba activate my_env\n",
    "\n",
    "# or with virtualenv\n",
    "python -m venv venv\n",
    "source venv/bin/activate\n",
    "\n",
    "# install packages\n",
    "pip install qdrant-client transformers datasets pandas numpy streamlit torch librosa \"torchaudio<0.12\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be6e1f5",
   "metadata": {},
   "source": [
    "### 3.2 Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e175c4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52253950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "from IPython.display import Audio as player\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d3a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_data = load_dataset(\n",
    "    \"audiofolder\", data_dir=\"data/latin_music/Audios/\", split=\"train\"\n",
    ").shuffle(seed=42).select(range(200))\n",
    "\n",
    "music_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e5dcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a15e7",
   "metadata": {},
   "source": [
    "#### Salsa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaa32fc",
   "metadata": {},
   "source": [
    "![salsa](https://lp-cms-production.imgix.net/2021-12/puerto-rico-salsa-lyma-rodrigues-discover-puerto-rico-191-3-15686-rm.jpg?auto=format&q=75&w=1920)\n",
    "\n",
    "Salsa is a popular music genre that originated in the 1960s in the Afro-Cuban and Puerto Rican communities of New York City. It is a fusion of various styles, including Cuban son, mambo, jazz, and other Latin American rhythms. Salsa music is known for its lively and energetic beats, intricate percussion, vibrant horn sections, and compelling dance rhythms.\n",
    "\n",
    "Some top artists associated with the salsa genre include:\n",
    "\n",
    "1. Celia Cruz\n",
    "2. Héctor Lavoe\n",
    "3. Willie Colón\n",
    "4. Marc Anthony\n",
    "5. Rubén Blades\n",
    "6. Gilberto Santa Rosa\n",
    "7. Eddie Palmieri\n",
    "8. Oscar D'León\n",
    "9. Ismael Rivera\n",
    "10. Tito Puente\n",
    "\n",
    "These are just a few notable artists, and there are many more talented musicians and bands that have contributed to the salsa genre throughout its history. The genre has evolved over time and continues to be popular worldwide, with artists from various countries and regions incorporating their own unique styles into salsa music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d000f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from pedalboard.io import AudioFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee9c3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<div align=\"center\">\n",
    "    <iframe width=\"700\" height=\"450\"\n",
    "    src=\"https://www.youtube.com/embed/vwGp16NXgQU\"\n",
    "    </iframe>\n",
    "</div>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4931934",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "salsa_song = 'data/latin_music/Audios/Salsa/salsa0009.mp3'\n",
    "\n",
    "with AudioFile(salsa_song) as f:\n",
    "    song = f.read(f.frames)[0]\n",
    "    display(player(song, rate=f.samplerate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475838e",
   "metadata": {},
   "source": [
    "#### Merengue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848573bb",
   "metadata": {},
   "source": [
    "![merengue](https://danceask.net/wp-content/uploads/2017/12/MERENGUE-DOMINICA-REPUBLIC.jpg)\n",
    "\n",
    "Merengue is a lively music and dance genre that originated in the Dominican Republic. It is characterized by its fast-paced rhythms, syncopated beats, and a prominent use of the accordion, güira (a metal scraper), and tambora (a two-headed drum). Merengue is known for its infectious energy and is popular across Latin America and the Caribbean.\n",
    "\n",
    "Here are some top artists associated with the merengue genre:\n",
    "\n",
    "1. Juan Luis Guerra\n",
    "2. Johnny Ventura\n",
    "3. Sergio Vargas\n",
    "4. Fernando Villalona\n",
    "5. Eddy Herrera\n",
    "6. Milly Quezada\n",
    "7. Toño Rosario\n",
    "8. Los Hermanos Rosario\n",
    "9. Wilfrido Vargas\n",
    "10. Los Toros Band\n",
    "\n",
    "These artists have made significant contributions to the merengue genre and have gained international recognition for their music. Merengue continues to evolve, incorporating modern elements while maintaining its traditional roots. The genre is widely celebrated for its catchy melodies, rhythmic dance patterns, and vibrant performances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c8c90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<div align=\"center\">\n",
    "    <iframe width=\"700\" height=\"450\"\n",
    "    src=\"https://www.youtube.com/embed/FGDs0_gUtfY\"\n",
    "    </iframe>\n",
    "</div>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81084f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merengue_song = 'data/latin_music/Audios/Merengue/merengue0200.mp3'\n",
    "\n",
    "with AudioFile(merengue_song) as f:\n",
    "    song = f.read(f.frames)[0]\n",
    "    display(player(song, rate=f.samplerate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2993c853",
   "metadata": {},
   "source": [
    "#### Bachata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0430acd0",
   "metadata": {},
   "source": [
    "![bachata](https://www.barcelo.com/guia-turismo/wp-content/uploads/2020/12/republica-dominicana_merengue-y-bachata_888_1.jpg)\n",
    "\n",
    "Bachata is a popular music genre that originated in the Dominican Republic. It emerged in the early 20th century and has since gained global popularity. Bachata is characterized by its melancholic and romantic lyrics, gentle guitar strumming, and a blend of African and European musical influences.\n",
    "\n",
    "Here are some top artists associated with the bachata genre:\n",
    "\n",
    "1. Romeo Santos\n",
    "2. Juan Luis Guerra\n",
    "3. Prince Royce\n",
    "4. Anthony Santos\n",
    "5. Aventura (group led by Romeo Santos)\n",
    "6. Raulín Rodríguez\n",
    "7. Zacarías Ferreira\n",
    "8. Frank Reyes\n",
    "9. Toby Love\n",
    "10. Monchy & Alexandra (duo)\n",
    "\n",
    "These artists have played a significant role in the development and popularization of bachata, both in the Dominican Republic and internationally. They have contributed to the evolution of the genre, incorporating elements from other styles such as pop, R&B, and urban music while staying true to the essence of bachata. Bachata has grown to become one of the most beloved Latin music genres, known for its emotional storytelling and heartfelt performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb5c90d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<div align=\"center\">\n",
    "    <iframe width=\"700\" height=\"450\"\n",
    "    src=\"https://www.youtube.com/embed/t808BgOjZPo\"\n",
    "    </iframe>\n",
    "</div>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3b1e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bachata_song = 'data/latin_music/Audios/Bachata/bachata0200.mp3'\n",
    "\n",
    "with AudioFile(bachata_song) as f:\n",
    "    song = f.read(f.frames)[0]\n",
    "    display(player(song, rate=f.samplerate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5e0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_data = music_data.cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abea800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = [music_data[i]['audio']['path'] for i in range(len(music_data))]\n",
    "ids = list(range(len(music_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ddf849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_data = music_data.add_column(\"paths\", paths)\n",
    "music_data = music_data.add_column(\"ids\", ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b85667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = music_data.features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "num_labels = len(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb261374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_names(label_num):\n",
    "    return id2label[str(label_num)]\n",
    "\n",
    "label_names = list(map(get_names, music_data['label']))\n",
    "music_data = music_data.add_column(\"label_names\", label_names)\n",
    "music_data[-10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f7481b",
   "metadata": {},
   "source": [
    "Some fake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065b124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb9479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_something = Faker()\n",
    "fake_something.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29da18cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_metadata(example):\n",
    "    path = example['paths']\n",
    "    genre = example['label_names']\n",
    "    example['metadata'] = {\n",
    "        \"artist\":   fake_something.name(),\n",
    "        \"song\":     \" \".join(fake_something.words()),\n",
    "        \"url_song\": path,\n",
    "        \"genre\":    genre,\n",
    "        \"year\":     fake_something.year(),\n",
    "        \"country\":  fake_something.country()\n",
    "    }\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f42589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_data = music_data.map(add_metadata)\n",
    "music_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851344d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_data[100]['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5835d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_data = music_data.remove_columns([\"paths\", 'label_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf41a1e-44eb-48c1-881c-ce5d865487eb",
   "metadata": {},
   "source": [
    "## 4. Vector Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a4d073",
   "metadata": {},
   "source": [
    "A vector database is a type of database designed to store and query high-dimensional vectors efficiently. In traditional [OLTP](https://www.ibm.com/topics/oltp) and [OLAP](https://www.ibm.com/topics/olap) databases, data is organized in rows and columns, and queries are performed based on the values in those columns. However, in certain applications including image recognition, natural language processing, and recommendation systems, data is often represented as vectors in a high-dimensional space. Here is a depiction of all three next to each other.\n",
    "\n",
    "![dbs](../images/databases.png)\n",
    "\n",
    "A vector in this context is a mathematical representation of an object or data point, where each element of the vector corresponds to a specific feature or attribute of the object. For example, in an image recognition system, a vector could represent an image, with each element of the vector representing a pixel value or a descriptor/characteristic of that pixel.\n",
    "\n",
    "Vector databases are optimized for **storing** and **querying** these high-dimensional vectors efficiently, often using specialized data structures and indexing techniques such as Hierarchical Navigable Small World (HNSW), Approximate Nearest Neighbors, and Product Quantization, among others. These databases enable fast similarity and semantic search while allowing users to find vectors that are the closest to a given query vector based on some distance metric. The most commonly used distance metrics are Euclidean Distance, Cosine Similarity, and Dot Product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf328aa",
   "metadata": {},
   "source": [
    "### Why do we need Vector Databases?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceeda7e",
   "metadata": {},
   "source": [
    "Vector databases play a crucial role in various applications that require similarity search, such as recommendation systems, content-based image retrieval, and personalized search. By taking advantage of their efficient indexing and searching techniques, vector databases enable faster and more accurate retrieval of similar vectors, which helps advance data analysis and decision-making.\n",
    "\n",
    "In addition, other benefits of using vector databases include:\n",
    "1. Efficient storage and indexing of high-dimensional data.\n",
    "3. Ability to handle large-scale datasets with billions or trillions of data points.\n",
    "4. Support for real-time analytics and queries.\n",
    "5. Ability to handle complex data types, such as images, videos, and natural language text.\n",
    "6. Improved performance and reduced latency in machine learning and AI applications.\n",
    "7. Reduced development and deployment time and cost compared to building a custom solution.\n",
    "\n",
    "Keep in mind that the specific benefits of using a vector database may vary depending on the use case of your organization and the features of the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3b42db",
   "metadata": {},
   "source": [
    "### Enter Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4c2029",
   "metadata": {},
   "source": [
    "Qdrant \"is a vector similarity search engine that provides a production-ready service with a convenient API to store, search, and manage points (i.e. vectors) with an additional payload.\" You can get started with plain python using the `qdrant-client`, pull the latest docker image of `qdrant` and connect to it locally, or try out Qdrant's Cloud free tier option until you are ready to make the full switch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eb0bcf",
   "metadata": {},
   "source": [
    "#### Overview of Qdrant's Architecture (High-Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa7b30c",
   "metadata": {},
   "source": [
    "![qdrant](../images/qdrant_overview_high_level.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9028813b",
   "metadata": {},
   "source": [
    "The diagram above represents a high-level overview of some of the main components of Qdrant. Here are the terminologies you should get familiar with.\n",
    "\n",
    "- [Collections](https://qdrant.tech/documentation/collections/): A collection is a named set of points (vectors with a payload) among which you can search. Vectors within the same collection must have the same dimensionality and be compared by a single metric.\n",
    "- Distance Metrics: These are used to measure similarities among vectors and they must be selected at the same time you are creating a collection. The choice of metric depends on the way vectors obtaining and, in particular, on the method of neural network encoder training.\n",
    "- [Points](https://qdrant.tech/documentation/points/): The points are the central entity that Qdrant operates with and they consist of a vector and an optional id and payload.\n",
    "- id: a unique identifier for your vectors.\n",
    "- Vector: a high-dimensional representation of data, for example, an image, a sound, a document, a video, etc.\n",
    "- [Payload](https://qdrant.tech/documentation/payload/): A payload additional data you can add to a vector.\n",
    "- [Storage](https://qdrant.tech/documentation/storage/): Qdrant can use one of  two options for storage, **In-memory** storage (Stores all vectors in RAM, has the highest speed since disk access is required only for persistence), or **Memmap** storage, (creates a virtual address space associated with the file on disk).\n",
    "- Clients: the programming languages you can use to connect to Qdrant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9192778a",
   "metadata": {},
   "source": [
    "#### How do we get started?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8847f",
   "metadata": {},
   "source": [
    "The open source version of Qdrant is available as a docker image and it can be pulled and run from any machine with docker installed. If you don't have Docker installed in your PC you can follow the instructions in the official documentation [here](https://docs.docker.com/get-docker/). After that, open your terminal start by downloading the image with the following command.\n",
    "\n",
    "```sh\n",
    "docker pull qdrant/qdrant\n",
    "```\n",
    "\n",
    "Next, initialize Qdrant with the following command, and you should be good to go.\n",
    "\n",
    "```sh\n",
    "docker run -p 6333:6333 \\\n",
    "    -v $(pwd)/qdrant_storage:/qdrant/storage \\\n",
    "    qdrant/qdrant\n",
    "```\n",
    "\n",
    "You should see something similar to the following image.\n",
    "\n",
    "![dockerqdrant](../images/docker_qdrant.png)\n",
    "\n",
    "If you experience any issues during the start process, here is a link to the [discord channel](https://qdrant.to/discord) where the Qdrant team is always available and happy to help.\n",
    "\n",
    "\n",
    "After your have your environment ready, let's get started with Qdrant.\n",
    "\n",
    "**Note:** At the time of writing, Qdrant supports Rust, GO, Python and TypeScript. We expect other programming languages to be added in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97611918",
   "metadata": {},
   "source": [
    "The two modules we'll use the most are the `QdrantClient` and the `models` one. The former allows us to connect to Qdrant or it allows us to run an in-memory database by switching the parameter `host=` to `\":memory:\"` (this is a great feature for testing in a CI/CD pipeline). We'll start by instantiating our client using `host=\"localhost\"` and `port=6333` (as it is the default we used earlier with docker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd36b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from qdrant_client.http.models import CollectionStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e8340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6ad6e",
   "metadata": {},
   "source": [
    "In OLTP and OLAP databases we call specific bundles of rows and columns **Tables**, but in vector databases the rows are known as vectors, the columns are known as dimensions, and the combination of the two (plus some metadata) as **collections**.\n",
    "\n",
    "In the same way in which we can create many tables in a database, we can create many collections in a vector-based database using a client. The key difference to note is that when we create a collection, we need to specify the width of the collection (i.e. the length of the vector or amount of dimensions) beforehand with the parameter `size=...`, as well as the similarity metric with the parameter `distance=...` (which can be changed later on).\n",
    "\n",
    "The distances currently supported by Qdrant are:\n",
    "- [**Cosine Similarity**](https://en.wikipedia.org/wiki/Cosine_similarity) - Cosine similarity is a way to measure how similar two things are. Think of it like a ruler that tells you how far apart two points are, but instead of measuring distance, it measures how similar two things are. It's often used with text to compare how similar two documents or sentences are to each other. The output of the cosine similarity ranges from 0 to 1, where 0 means the two things are completely dissimilar, and 1 means the two things are exactly the same. It's a straightforward and effective way to compare two things!\n",
    "- [**Dot Product**](https://en.wikipedia.org/wiki/Dot_product) - The dot product similarity metric is another way of measuring how similar two things are, like cosine similarity. It's often used in machine learning and data science when working with numbers. The dot product similarity is calculated by multiplying the values in two sets of numbers, and then adding up those products. The higher the sum, the more similar the two sets of numbers are. So, it's like a scale that tells you how closely two sets of numbers match each other.\n",
    "- [**Euclidean Distance**](https://en.wikipedia.org/wiki/Euclidean_distance) - Euclidean distance is a way to measure the distance between two points in space, similar to how we measure the distance between two places on a map. It's calculated by finding the square root of the sum of the squared differences between the two points' coordinates. This distance metric is commonly used in machine learning to measure how similar or dissimilar two data points are or, in other words, to understand how far apart they are.\n",
    "\n",
    "Let's create our first collection and have the vectors be of with 100 and the distance set to **Cosine Similarity**. Please note that, at the time of writing, Qdrant supports cosine similarity, dot product and euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed013a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_collection = \"first_collection\"\n",
    "\n",
    "first_collection = client.recreate_collection(\n",
    "    collection_name=my_collection,\n",
    "    vectors_config=models.VectorParams(size=100, distance=models.Distance.COSINE)\n",
    ")\n",
    "print(first_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dbe719",
   "metadata": {},
   "source": [
    "We can extract information related to the health of our collection by getting the collection. In addition, we can use this information for testing purposes, which can be very beneficial while in development mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575af37e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection_info = client.get_collection(collection_name=my_collection)\n",
    "collection_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf39f84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert collection_info.status == CollectionStatus.GREEN\n",
    "assert collection_info.vectors_count == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beb0640",
   "metadata": {},
   "source": [
    "There's a couple of things to notice from what we have done so far.\n",
    "- The first is that when we initiated our docker image, we created a local directory called, `qdrant_storage`, and this is where all of our collections, plus their metadata, will be saved at. You can have a look at that directory in a *nix system with `tree qdrant_storage -L 2`, and something similar to the following should come up for you.\n",
    "    ```bash\n",
    "    qdrant_storage\n",
    "    ├── aliases\n",
    "    │   └── data.json\n",
    "    ├── collections\n",
    "    │   └── my_first_collection\n",
    "    └── raft_state\n",
    "    ```\n",
    "- The second is that we used `client.recreate_collection` and this command, as the name implies, can be used more than once for a collection with the same name, so be careful no to recreate a collection that you did not intend to recreate. To create a brand new collection where trying to recreate another of the same name would throw an error, we would use `client.create_collection` instead.\n",
    "- Our collection can only hold vectors of 100 dimensions and the distance metric has been set to Cosine Similarity.\n",
    "\n",
    "Now that we know how to create collections, let's create a bit of fake data and add some vectors to our collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f33ac30",
   "metadata": {},
   "source": [
    "#### Adding Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb5008a",
   "metadata": {},
   "source": [
    "The points are the central entity that Qdrant operates with, and these points contain records consisting of a vector, an optional id and an optional payload (which we'll talk more about in the next section).\n",
    "\n",
    "The optional id can be represented by unassigned integers or UUIDs but, for our use case, we will use a straightforward range of numbers.\n",
    "\n",
    "Let's create a matrix of fake data containing 1,000 rows and 100 columns while representing the values of our vectors as `float64` numbers between -1 and 1. For simplicity, let's imagine that each of these vectors represents one of our favorite songs, and that each columns represents a unique characteristic of the artists/bands we love, for example, the tempo, the beats, the pitch of the voice of the singer(s), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab90263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.random.uniform(low=-1.0, high=1.0, size=(1_000, 100))\n",
    "type(data[0, 0]), data[:2, :20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c74ac",
   "metadata": {},
   "source": [
    "Let's know create an index for our vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7774048e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = list(range(len(data)))\n",
    "index[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b383b5",
   "metadata": {},
   "source": [
    "Once the collection has been created, we can fill it in with the command `client.upsert()`. We need the collection's name and the appropriate process from our `models` module, in this case, [`Batch`](https://qdrant.tech/documentation/points/#upload-points).\n",
    "\n",
    "One thing to note is that Qdrant can only take in native Python iterables like lists and tuples. This is why you'll notice the `.tolist()` method attached to our `data` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a65790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.upsert(\n",
    "    collection_name=my_collection,\n",
    "    points=models.Batch(\n",
    "        ids=index,\n",
    "        vectors=data.tolist()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19292024",
   "metadata": {},
   "source": [
    "We can retrieve specific points based on their ID (for example, artist X with ID 1000) and get some additional information from that result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590e82b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.retrieve(\n",
    "    collection_name=my_collection,\n",
    "    ids=[100],\n",
    "    with_vectors=True # we can turn this on and off depending on our needs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589fee56",
   "metadata": {},
   "source": [
    "We can also update our collection one point at a time, for example, as new data comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd8fbbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_song():\n",
    "    return np.random.uniform(low=-1.0, high=1.0, size=100).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6add5b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.upsert(\n",
    "    collection_name=my_collection,\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=1000,\n",
    "            vector=create_song(),\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cab845",
   "metadata": {},
   "source": [
    "We can also delete it in a straightforward fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b76cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this will show the amount of vectors BEFORE deleting them\n",
    "client.count(\n",
    "    collection_name=my_collection, \n",
    "    exact=True,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1f7181",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.delete(\n",
    "    collection_name=my_collection,\n",
    "    points_selector=models.PointIdsList(\n",
    "        points=[1000],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42768fef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this will show the amount of vectors AFTER deleting them\n",
    "client.count(\n",
    "    collection_name=my_collection, \n",
    "    exact=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a87f959",
   "metadata": {},
   "source": [
    "#### Payloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cb19a",
   "metadata": {},
   "source": [
    "Qdrant has incredible features on top of speed and reliability, and one of its most useful ones is without a doubt the ability to store additional information along with vectors. In Qdrant terminology, this information is considered a payload and it is represented as JSON objects. In addition, not only can you get this information back when you search in the database, but you can also filter your search by the parameters in the payload, and we'll see how in a second.\n",
    "\n",
    "Imagine the fake vectors we created actually represented a song. If we were building a recommender system for songs then, naturally, the things we would want to get back would be the song itself, the artist, maybe the genre, and so on.\n",
    "\n",
    "What we'll do here is to take advantage of `faker` again and create a bit of information to add to our payload and see how this functionality works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c2435e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    payload.append(\n",
    "        {\n",
    "            \"artist\":   fake_something.name(),\n",
    "            \"song\":     \" \".join(fake_something.words()),\n",
    "            \"url_song\": fake_something.url(),\n",
    "            \"year\":     fake_something.year(),\n",
    "            \"country\":  fake_something.country()\n",
    "        }\n",
    "    )\n",
    "\n",
    "payload[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78cf48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.upsert(\n",
    "    collection_name=my_collection,\n",
    "    points=models.Batch(\n",
    "        ids=index,\n",
    "        vectors=data.tolist(),\n",
    "        payloads=payload\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcfc844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resutls = client.retrieve(\n",
    "    collection_name=my_collection,\n",
    "    ids=[10, 50, 100, 500],\n",
    "    with_vectors=False\n",
    ")\n",
    "resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c793af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resutls[0].payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36b4645",
   "metadata": {},
   "source": [
    "#### Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3135ece9",
   "metadata": {},
   "source": [
    "Now that we have our vectors with an ID and a payload, we can explore a few of ways in which we can search for content when, in our use case, new music gets selected. Let's check it out.\n",
    "\n",
    "Say, for example, that a new song comes in and our model immediately transforms it into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a85293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "living_la_vida_loca = create_song()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872e021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=living_la_vida_loca,\n",
    "    limit=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f1c7df",
   "metadata": {},
   "source": [
    "Now imagine that we only want Australian songs recommended to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5026c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aussie_songs = models.Filter(\n",
    "    must=[models.FieldCondition(key=\"country\", match=models.MatchValue(value=\"Australia\"))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2697e5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=living_la_vida_loca,\n",
    "    query_filter=aussie_songs,\n",
    "    limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1f3af8",
   "metadata": {},
   "source": [
    "Lastly, say we want aussie songs but we don't care how new or old these songs are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2653bdca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.search(\n",
    "    collection_name=my_collection,\n",
    "    query_vector=living_la_vida_loca,\n",
    "    query_filter=aussie_songs,\n",
    "    with_payload=models.PayloadSelectorExclude(exclude=[\"year\"]),\n",
    "    limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc1bb0e",
   "metadata": {},
   "source": [
    "As you can see, you can apply a wide-range of filtering methods to allows your users to take more control of the recommendations they are being served.\n",
    "\n",
    "If you wanted to clear out the payload and upload a new for the same vectors, you can use `client.clear_payload()` as in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0df80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.clear_payload(\n",
    "    collection_name=my_collection,\n",
    "    points_selector=models.PointIdsList(\n",
    "        points=index,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4299ff02",
   "metadata": {},
   "source": [
    "## 5. Models and Vector Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39590fc",
   "metadata": {},
   "source": [
    "In the context of audio data, embeddings and transformers are used to process the sound waves and extract features that are useful for training machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58320005",
   "metadata": {},
   "source": [
    "### What are transformers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc1463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoFeatureExtractor, AutoModelForAudioClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b61764",
   "metadata": {},
   "source": [
    "Transformers are a type of neural network used for natural language processing, but they can also be used for processing audio data by breaking the sound waves into smaller parts and learning how those parts fit together to form meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7de2090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc51dc1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\", num_labels=num_labels, label2id=label2id, id2label=id2label\n",
    ")#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a027d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = music_data[23]['audio'][\"array\"]\n",
    "player(sample, rate=16_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9059a2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = feature_extractor(\n",
    "    sample, sampling_rate=feature_extractor.sampling_rate, \n",
    "    return_tensors=\"pt\", padding=True, return_attention_mask=True,\n",
    "    max_length=16_000, truncation=True\n",
    ")#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f9e4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds = model(**inputs).logits\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46299ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.argmax(preds).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78781af6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.config.id2label??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ec0602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_class_ids = torch.argmax(preds).item()\n",
    "predicted_label = model.config.id2label[str(predicted_class_ids)]\n",
    "predicted_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed0716",
   "metadata": {},
   "source": [
    "While this isn't the most confident model in the world, it did predict bachata correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932d5d58",
   "metadata": {},
   "source": [
    "### What are Embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64dc0f",
   "metadata": {},
   "source": [
    "Embeddings are a way of representing audio data as vectors or numbers, which makes it easier for machine learning algorithms to process and analyze them. These are the vectors that we will store in Qdrant in a second."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bec30a",
   "metadata": {},
   "source": [
    "### Extracting Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1df592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"facebook/wav2vec2-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9504730a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embs = model(**inputs.to(device)).last_hidden_state\n",
    "embs.size(), embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c250b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embs.mean(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036bdc80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pooled_emb = embs.mean(dim=1)\n",
    "print(pooled_emb.shape)\n",
    "print(f\"Max Value: {pooled_emb.max()}\") \n",
    "print(f\"Min Value: {pooled_emb.min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10739c8",
   "metadata": {},
   "source": [
    "Now let's do it with our whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c44783",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_features(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    return feature_extractor(\n",
    "        audio_arrays, sampling_rate=feature_extractor.sampling_rate, return_tensors=\"pt\",\n",
    "        max_length=16000, truncation=True, padding=True, return_attention_mask=True,\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a8ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_features = music_data.map(get_features, batched=True, batch_size=50)\n",
    "music_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f827f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_features.set_format(\"torch\", columns=[\"input_values\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b3010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = {k: v.to(device) for k, v in music_features[:50].items() if k in feature_extractor.model_input_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406bd000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_extractor.model_input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2115941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_output = model(**inputs).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c77347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_output.mean(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34497130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_embeddings(batch):\n",
    "    inputs = {k: v.to(device) for k, v in batch.items() if k in feature_extractor.model_input_names}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_output = model(**inputs).last_hidden_state\n",
    "    \n",
    "    pooled_embeds = model_output.mean(dim=1)\n",
    "    \n",
    "    return {\"embedding\": pooled_embeds.cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0044ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_embs = music_features.map(extract_embeddings, batched=True, batch_size=50)\n",
    "music_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488ebf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(\n",
    "    \"data/recsys/music_embs\",\n",
    "    np.array(music_embs['embedding']),\n",
    "    allow_pickle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39049c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.load(\"data/recsys/music_embs.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8904f6c",
   "metadata": {},
   "source": [
    "## 6. Putting it All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baece8b0",
   "metadata": {},
   "source": [
    "Now that we have the data we need, it is time to put it to the test with a UI built on streamlit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8e70a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de40ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = list(music_data['metadata'])\n",
    "payload[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48163209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d03102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.Series(payload).to_csv(\"data/recsys/payload.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc02b88",
   "metadata": {},
   "source": [
    "### 6.1 Basics of Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff4a899",
   "metadata": {},
   "source": [
    "Recommendation systems are algorithms and techniques used to suggest items or content to users based on their preferences, historical data, or behavior. These systems aim to provide personalized recommendations to users, helping them discover new items of interest and enhancing their overall user experience. Recommendation systems are widely used in various domains such as e-commerce, streaming platforms, social media, and more.\n",
    "\n",
    "Here are a few examples of recommendation systems related to deep learning:\n",
    "\n",
    "1. Collaborative Filtering with Neural Networks: Collaborative filtering is a common recommendation approach that predicts user preferences based on their similarity to other users. Deep learning techniques, such as neural networks, can be applied to learn complex patterns and representations from user-item interactions to improve collaborative filtering recommendations.\n",
    "\n",
    "2. Content-based Recommendation with Deep Learning: Content-based recommendation systems utilize the characteristics or features of items to make recommendations. Deep learning models, such as convolutional neural networks (CNNs) or recurrent neural networks (RNNs), can be used to extract high-level representations from item features, such as images, text, or audio, and make personalized recommendations based on user preferences.\n",
    "\n",
    "3. Neural Matrix Factorization: Matrix factorization is a popular technique for recommendation systems that factorizes the user-item interaction matrix to capture latent factors. Deep learning models, such as autoencoders or neural networks with multiple layers, can be used to model the matrix factorization process and generate more accurate recommendations.\n",
    "\n",
    "4. Sequence-based Recommendation with Recurrent Neural Networks (RNNs): In scenarios where sequential user interactions or behaviors are important, RNNs can be employed to model sequential dependencies and capture user preferences over time. This approach is useful for recommendation systems in domains like music, video, or news, where the order of items matters.\n",
    "\n",
    "5. Hybrid Recommendation Systems: Deep learning models can be combined with traditional recommendation techniques, such as collaborative filtering or content-based filtering, to create hybrid recommendation systems. These systems leverage the strengths of different approaches to provide more accurate and diverse recommendations.\n",
    "\n",
    "It's worth noting that these examples are just a few instances of how deep learning can be applied in recommendation systems. The field is evolving rapidly, and researchers continue to explore new architectures and techniques to improve the quality and effectiveness of recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5412a67",
   "metadata": {},
   "source": [
    "### 6.2 Loading Up Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e78b29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# payload = pd.read_csv(\"../data/recsys/payload.csv\").tolist()\n",
    "# vectors = np.load(\"../data/recsys/music_embs.npy\")\n",
    "# client = QdrantClient(\"localhost\", port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caecbe97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dimensions = music_embs[0]['embedding'].shape[0]\n",
    "dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41210967-3ec3-49b2-abd0-e7280eef617c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.recreate_collection(\n",
    "    collection_name=\"music_recsys\",\n",
    "    vectors_config=models.VectorParams(size=dimensions, distance=models.Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ee497-edae-467d-8e6f-984de17f40e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection_info = client.get_collection(collection_name=\"music_recsys\")\n",
    "collection_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49169591-ef42-4379-a63b-dfd5b8a6961a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import CollectionStatus\n",
    "\n",
    "assert collection_info.status == CollectionStatus.GREEN\n",
    "assert collection_info.vectors_count == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe184c5-9858-4cef-9223-ed5540f92702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.upsert(\n",
    "    collection_name=\"music_recsys\",\n",
    "    points=models.Batch(\n",
    "        ids=music_data['ids'],\n",
    "        vectors=music_embs['embedding'].tolist(),\n",
    "        payloads=payload\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c9e99d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877221df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = glob(\"data/latin_music/Audios/*/*.mp3\")\n",
    "files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a9cef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = choice(files)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ab90d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with AudioFile(sample) as f:\n",
    "    print(f.samplerate)\n",
    "    print(f.num_channels)\n",
    "    print(f.read(3))\n",
    "    song = f.read(f.frames)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ecd35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "player(song, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f5659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "song.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57699893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "new_input = feature_extractor(\n",
    "    song, sampling_rate=feature_extractor.sampling_rate, return_tensors=\"pt\",\n",
    "    padding=True, return_attention_mask=True, max_length=16_000, truncation=True\n",
    ")#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf4a2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\", num_labels=num_labels, label2id=label2id, id2label=id2label,\n",
    ")#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd75333d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**new_input).logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855cb7f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_class_ids = torch.argmax(logits).item()\n",
    "predicted_label = model.config.id2label[str(predicted_class_ids)]\n",
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8f20f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_4_embs = AutoModel.from_pretrained(\"facebook/wav2vec2-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196cca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66d5fd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_output = model_4_embs(**new_input).last_hidden_state\n",
    "    sample_embeds = model_output.mean(dim=1).cpu().numpy()\n",
    "sample_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1854a84-fa12-44bf-bbf6-a1939f822b01",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = client.search(\n",
    "    collection_name=\"music_recsys\",\n",
    "    query_vector=sample_embeds[0].tolist(),\n",
    "    limit=10, \n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ecd379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results[0].payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61edfbef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in results:\n",
    "    file = i.payload['url_song']\n",
    "    with AudioFile(file) as f:\n",
    "        a_song = f.read(f.frames)[0]\n",
    "    display(player(a_song, rate=44100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40521d74-0175-4347-94ae-bff972ed1bf0",
   "metadata": {},
   "source": [
    "### 6.3 Building a UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4b3745-1011-4a6a-b9a2-aae128c4ea88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile recsys_app.py\n",
    "\n",
    "from transformers import AutoModel, AutoFeatureExtractor\n",
    "from qdrant_client import QdrantClient\n",
    "from pedalboard.io import AudioFile\n",
    "import streamlit as st\n",
    "import torch\n",
    "\n",
    "st.title(\"Music Recommendation App\")\n",
    "st.markdown(\"Upload your favorite songs and get a list of recommendations from our database of music.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained('facebook/wav2vec2-base').to(device)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "client = QdrantClient(\"localhost\", port=6333)\n",
    "\n",
    "music_file = st.file_uploader(label=\"📀 Music file 🎸\",)\n",
    "\n",
    "if music_file:\n",
    "    st.audio(music_file)\n",
    "\n",
    "    with AudioFile(music_file) as f:\n",
    "        a_song = f.read(f.frames)[0]\n",
    "\n",
    "    inputs = feature_extractor(\n",
    "        a_song, sampling_rate=feature_extractor.sampling_rate, return_tensors=\"pt\",\n",
    "        padding=True, return_attention_mask=True, max_length=16_000, truncation=True\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "    vectr = last_hidden_state.mean(dim=1).cpu().numpy()[0]\n",
    "\n",
    "    st.markdown(\"## Real Recommendations\")\n",
    "    results = client.search(collection_name=\"music_recsys\", query_vector=vectr, limit=4)\n",
    "    col1, col2 = st.columns(2)\n",
    "\n",
    "    with col1:\n",
    "        st.header(f\"Genre: {results[0].payload['genre']}\")\n",
    "        st.subheader(f\"Artist: {results[0].payload['artist']}\")\n",
    "        st.audio(results[0].payload[\"url_song\"])\n",
    "        \n",
    "        st.header(f\"Genre: {results[1].payload['genre']}\")\n",
    "        st.subheader(f\"Artist: {results[1].payload['artist']}\")\n",
    "        st.audio(results[1].payload[\"url_song\"])\n",
    "\n",
    "    with col2:\n",
    "        st.header(f\"Genre: {results[2].payload['genre']}\")\n",
    "        st.subheader(f\"Artist: {results[2].payload['artist']}\")\n",
    "        st.audio(results[2].payload[\"url_song\"])\n",
    "        \n",
    "        st.header(f\"Genre: {results[3].payload['genre']}\")\n",
    "        st.subheader(f\"Artist: {results[3].payload['artist']}\")\n",
    "        st.audio(results[3].payload[\"url_song\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b90973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!streamlit run recsys_app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba5243-7902-49a9-b0c0-04670eef4d3a",
   "metadata": {},
   "source": [
    "## 7. Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c2f33b",
   "metadata": {},
   "source": [
    "We have explored a bit of the fascinating world of vector databases, natural language processing, transformers, and embeddings. In this tutorial we learned that (1) vector databases provide efficient storage and retrieval of high-dimensional vectors, making them ideal for similarity-based search tasks. (2) Signal processing enables us to understand and process audio data, opening up possibilities for different kinds of useful applications for digital technologies. (3) Transformers, with their attention mechanism, capture long-range dependencies in different modalities and achieve incredible results in different tasks. Finally, embeddings encode data into dense vectors, capturing semantic relationships and enabling powerful understanding capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
